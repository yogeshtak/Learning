{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Topic_model_NLP.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyOwd9xMQFE+5mbbr36Fn5h4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/yogeshtak/Learning/blob/master/Topic_model_NLP.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QeTaJTuULedS"
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "data = pd.read_csv('Comments1.csv')\n",
        "data.dropna(subset=['comment1'], inplace=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BH9SnMgxLwye",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "cfec643c-031f-43fa-dbe8-07fd98b7bca4"
      },
      "source": [
        "data.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Response_ID</th>\n",
              "      <th>comment1</th>\n",
              "      <th>comment2</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>cf561c54-f8e3-cd65-7a71-2b7d8e00078d</td>\n",
              "      <td>selling more product</td>\n",
              "      <td>having enough sales to get through</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>e95e599f-2ff9-8751-72ba-6e75abaac643</td>\n",
              "      <td>More employee retention.</td>\n",
              "      <td>None at all.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>e1959062-e65a-4b7b-b947-a7be889d0b9b</td>\n",
              "      <td>customer insights</td>\n",
              "      <td>COVID 19</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>5f11e0f5-4820-3cf8-3dd0-d73ae2f0b10c</td>\n",
              "      <td>more customers</td>\n",
              "      <td>Keeping all the employees safe</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>13a6537f-c7ea-f76a-8a5a-648d2abd4ea8</td>\n",
              "      <td>Everything</td>\n",
              "      <td>People getting sick</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                            Response_ID  ...                            comment2\n",
              "0  cf561c54-f8e3-cd65-7a71-2b7d8e00078d  ...  having enough sales to get through\n",
              "1  e95e599f-2ff9-8751-72ba-6e75abaac643  ...                        None at all.\n",
              "2  e1959062-e65a-4b7b-b947-a7be889d0b9b  ...                            COVID 19\n",
              "3  5f11e0f5-4820-3cf8-3dd0-d73ae2f0b10c  ...      Keeping all the employees safe\n",
              "4  13a6537f-c7ea-f76a-8a5a-648d2abd4ea8  ...                People getting sick \n",
              "\n",
              "[5 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1nejCKKULyrD",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 258
        },
        "outputId": "787af88d-856a-46e8-81d8-979e619a9225"
      },
      "source": [
        "data_comment5 = data[['comment1']]\n",
        "data_comment5['index'] = data_comment5.index\n",
        "data5 = data_comment5\n",
        "\n",
        "print(len(data5))\n",
        "print(data5[:5])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "217\n",
            "                   comment1  index\n",
            "0     selling more product       0\n",
            "1  More employee retention.      1\n",
            "2         customer insights      2\n",
            "3           more customers       3\n",
            "4               Everything       4\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  \n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2LSifFMbMdjo",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "c5ce139a-3d9c-43db-9781-47615116fec3"
      },
      "source": [
        "import gensim\n",
        "from gensim.utils import simple_preprocess\n",
        "from gensim.parsing.preprocessing import STOPWORDS\n",
        "from nltk.stem import WordNetLemmatizer, SnowballStemmer\n",
        "from nltk.stem.porter import *\n",
        "import numpy as np\n",
        "np.random.seed(2020)\n",
        "\n",
        "import nltk\n",
        "nltk.download('wordnet')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jjXlx4S0Oga-"
      },
      "source": [
        "stemmer = SnowballStemmer('english')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P6RAiGwaM-Ng"
      },
      "source": [
        "def lemmatize_stemming(text):\n",
        "  return stemmer.stem(WordNetLemmatizer().lemmatize(text, pos='v'))\n",
        "\n",
        "def preprocess(text):\n",
        "  result = []\n",
        "  for token in gensim.utils.simple_preprocess(text):\n",
        "    if token not in gensim.parsing.preprocessing.STOPWORDS and len(token) >3:\n",
        "      result.append(lemmatize_stemming(token))\n",
        "  return result\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z4U_E7FdNiW-",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        },
        "outputId": "b66071af-c94c-4204-ebb2-069daf5cb62e"
      },
      "source": [
        "comment_sample = data5[data5['index']==156].values[0][0]\n",
        "\n",
        "print('Original Text: ')\n",
        "words = []\n",
        "for word in comment_sample.split(' '):\n",
        "  words.append(word)\n",
        "print(words)\n",
        "print('\\n\\n tokenized and lemmatized comment: ')\n",
        "print(preprocess(comment_sample))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Original Text: \n",
            "['I', 'would', 'be.very', 'impressed', 'cause', 'I', 'worked', 'hard', 'for', 'it\\n']\n",
            "\n",
            "\n",
            " tokenized and lemmatized comment: \n",
            "['impress', 'caus', 'work', 'hard']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0Pf076zPONgb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "d7531000-e883-4488-b597-e2dc02f6b8f9"
      },
      "source": [
        "processed_comment5 = data5['comment1'].map(preprocess)\n",
        "processed_comment5[:10]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0                                      [sell, product]\n",
              "1                                    [employe, retent]\n",
              "2                                    [custom, insight]\n",
              "3                                             [custom]\n",
              "4                                                   []\n",
              "5    [think, help, higher, compani, actual, listen,...\n",
              "6    [think, have, peopl, avail, interact, custom, ...\n",
              "7                            [avail, comprehens, tool]\n",
              "8                      [know, work, safe, work, place]\n",
              "9            [great, great, great, good, night, sleep]\n",
              "Name: comment1, dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CAmBlcJ_PbgL"
      },
      "source": [
        "dictionary = gensim.corpora.Dictionary(processed_comment5)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JW4zPAKRQyw9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "84e17ebc-c440-41db-97f7-37b89c0c6682"
      },
      "source": [
        "count = 0\n",
        "\n",
        "for k,v in dictionary.iteritems():\n",
        "  print(k,v)\n",
        "  count+=1\n",
        "  if count > 10:\n",
        "    break"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0 product\n",
            "1 sell\n",
            "2 employe\n",
            "3 retent\n",
            "4 custom\n",
            "5 insight\n",
            "6 actual\n",
            "7 appeas\n",
            "8 compani\n",
            "9 donor\n",
            "10 help\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9_Ls0AFqQ8Mi"
      },
      "source": [
        "dictionary.filter_extremes(no_below=15, no_above=0.5, keep_n=100000)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MCLwC_lARFVH",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "d94e8bf4-d653-4eb1-836b-2ce057f6f46f"
      },
      "source": [
        "bow_corpus = [dictionary.doc2bow(doc) for doc in processed_comment5]\n",
        "bow_corpus[11]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[(1, 1), (3, 1)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "plVmBJzcRSEi",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "63a282b5-5fc8-4d7d-89f4-8ac66000a546"
      },
      "source": [
        "bow_doc_11 = bow_corpus[11]\n",
        "\n",
        "for i in range(len(bow_doc_11)):\n",
        "  print(\"Word{} (\\\"{}\\\") appears {} time.\".format(bow_doc_11[i][0], dictionary[bow_doc_11[i][0]], bow_doc_11[i][1]))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Word1 (\"insight\") appears 1 time.\n",
            "Word3 (\"better\") appears 1 time.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MSzw-VAYSOFF"
      },
      "source": [
        "from gensim import corpora, models\n",
        "tfidf = models.TfidfModel(bow_corpus)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5Bf4gfyZSkRi"
      },
      "source": [
        "corpus_tfidf = tfidf[bow_corpus]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LiFDLixJSsev",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "51562bc6-1a96-4fee-ff63-7d04c1dad715"
      },
      "source": [
        "from pprint import pprint\n",
        "\n",
        "for comment in corpus_tfidf:\n",
        "  pprint(comment)\n",
        "  break"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_5LZphroS2cG"
      },
      "source": [
        "lda_model = gensim.models.LdaMulticore(bow_corpus, num_topics=10, id2word=dictionary, passes=2, workers=2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8i0X-AitS69u",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 357
        },
        "outputId": "e98671e4-583f-44b4-82af-f658c700aea8"
      },
      "source": [
        "for idx, topic in lda_model.print_topics(-1):\n",
        "    print('Topic: {} \\nWords: {}'.format(idx, topic))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Topic: 0 \n",
            "Words: 0.950*\"feedback\" + 0.012*\"custom\" + 0.012*\"better\" + 0.012*\"collect\" + 0.012*\"insight\"\n",
            "Topic: 1 \n",
            "Words: 0.534*\"better\" + 0.405*\"insight\" + 0.020*\"custom\" + 0.020*\"feedback\" + 0.020*\"collect\"\n",
            "Topic: 2 \n",
            "Words: 0.372*\"insight\" + 0.355*\"custom\" + 0.212*\"collect\" + 0.058*\"better\" + 0.003*\"feedback\"\n",
            "Topic: 3 \n",
            "Words: 0.873*\"better\" + 0.082*\"collect\" + 0.031*\"insight\" + 0.007*\"custom\" + 0.007*\"feedback\"\n",
            "Topic: 4 \n",
            "Words: 0.802*\"custom\" + 0.115*\"insight\" + 0.057*\"better\" + 0.021*\"collect\" + 0.005*\"feedback\"\n",
            "Topic: 5 \n",
            "Words: 0.439*\"collect\" + 0.356*\"feedback\" + 0.131*\"better\" + 0.065*\"insight\" + 0.010*\"custom\"\n",
            "Topic: 6 \n",
            "Words: 0.833*\"custom\" + 0.129*\"insight\" + 0.025*\"collect\" + 0.006*\"better\" + 0.006*\"feedback\"\n",
            "Topic: 7 \n",
            "Words: 0.536*\"custom\" + 0.190*\"feedback\" + 0.186*\"insight\" + 0.044*\"better\" + 0.044*\"collect\"\n",
            "Topic: 8 \n",
            "Words: 0.339*\"custom\" + 0.295*\"insight\" + 0.295*\"feedback\" + 0.058*\"better\" + 0.014*\"collect\"\n",
            "Topic: 9 \n",
            "Words: 0.426*\"collect\" + 0.252*\"custom\" + 0.217*\"feedback\" + 0.067*\"insight\" + 0.038*\"better\"\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TCk9dBi8S-c9"
      },
      "source": [
        "lda_model_tfidf = gensim.models.LdaMulticore(corpus_tfidf, num_topics=10, id2word=dictionary, passes=2, workers=4)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3X4WKl6CTObM",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        },
        "outputId": "6cef615f-1f85-4a37-cbdf-fafc2b7bb95a"
      },
      "source": [
        "for idx, topic in lda_model_tfidf.print_topics(-1):\n",
        "    print('Topic: {} Word: {}'.format(idx, topic))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Topic: 0 Word: 0.967*\"custom\" + 0.019*\"better\" + 0.005*\"feedback\" + 0.005*\"collect\" + 0.005*\"insight\"\n",
            "Topic: 1 Word: 0.513*\"insight\" + 0.247*\"custom\" + 0.153*\"better\" + 0.044*\"feedback\" + 0.043*\"collect\"\n",
            "Topic: 2 Word: 0.367*\"custom\" + 0.314*\"feedback\" + 0.107*\"better\" + 0.107*\"collect\" + 0.107*\"insight\"\n",
            "Topic: 3 Word: 0.413*\"collect\" + 0.336*\"insight\" + 0.203*\"custom\" + 0.038*\"better\" + 0.010*\"feedback\"\n",
            "Topic: 4 Word: 0.472*\"insight\" + 0.218*\"better\" + 0.149*\"feedback\" + 0.112*\"custom\" + 0.048*\"collect\"\n",
            "Topic: 5 Word: 0.330*\"insight\" + 0.326*\"feedback\" + 0.263*\"custom\" + 0.067*\"collect\" + 0.014*\"better\"\n",
            "Topic: 6 Word: 0.915*\"better\" + 0.046*\"custom\" + 0.025*\"feedback\" + 0.007*\"collect\" + 0.007*\"insight\"\n",
            "Topic: 7 Word: 0.769*\"feedback\" + 0.168*\"custom\" + 0.044*\"better\" + 0.009*\"insight\" + 0.009*\"collect\"\n",
            "Topic: 8 Word: 0.640*\"custom\" + 0.143*\"insight\" + 0.099*\"feedback\" + 0.086*\"collect\" + 0.032*\"better\"\n",
            "Topic: 9 Word: 0.649*\"collect\" + 0.184*\"feedback\" + 0.099*\"custom\" + 0.059*\"insight\" + 0.008*\"better\"\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LH9d0W0NTQj7"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}